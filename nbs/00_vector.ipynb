{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client\n",
    "\n",
    "> A module for writing and querying vectors to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv()) \n",
    "service_url  = os.environ['TIMESCALE_SERVICE_URL'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncpg\n",
    "import uuid\n",
    "from pgvector.asyncpg import register_vector\n",
    "from typing import (List, Optional, Union, Dict, Tuple)\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "SEARCH_RESULT_ID_IDX = 0\n",
    "SEARCH_RESULT_METADATA_IDX = 1\n",
    "SEARCH_RESULT_CONTENTS_IDX = 2\n",
    "SEARCH_RESULT_EMBEDDING_IDX = 3\n",
    "SEARCH_RESULT_DISTANCE_IDX = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class QueryBuilder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        table_name: str,\n",
    "        num_dimensions: int,\n",
    "        distance_type: str = 'cosine') -> None:\n",
    "        \"\"\"\n",
    "        Initializes a base Vector object to generate queries for vector clients.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): The name of the table.\n",
    "            num_dimensions (int): The number of dimensions for the embedding vector.\n",
    "            distance_type (str, optional): The distance type for indexing. Default is 'cosine' or '<=>'.\n",
    "        \"\"\"\n",
    "        self.table_name = table_name\n",
    "        self.num_dimensions = num_dimensions\n",
    "        if distance_type == 'cosine' or distance_type == '<=>':\n",
    "            self.distance_type = '<=>'\n",
    "        elif distance_type == 'euclidean' or distance_type == '<->' or distance_type == 'l2':\n",
    "            self.distance_type = '<->'\n",
    "        else:\n",
    "            raise ValueError(f\"unrecognized distance_type {distance_type}\")\n",
    "\n",
    "    def _quote_ident(self, ident):\n",
    "        \"\"\"\n",
    "        Quotes an identifier to prevent SQL injection.\n",
    "\n",
    "        Args:\n",
    "            ident (str): The identifier to be quoted.\n",
    "\n",
    "        Returns:\n",
    "            str: The quoted identifier.\n",
    "        \"\"\"\n",
    "        return '\"{}\"'.format(ident.replace('\"', '\"\"'))\n",
    "\n",
    "    def get_row_exists_query(self):\n",
    "        \"\"\"\n",
    "        Generates a query to check if any rows exist in the table.\n",
    "\n",
    "        Returns:\n",
    "            str: The query to check for row existence.\n",
    "        \"\"\"\n",
    "        return \"SELECT 1 FROM {table_name} LIMIT 1\".format(table_name=self._quote_ident(self.table_name))\n",
    "\n",
    "    def get_upsert_query(self):\n",
    "        \"\"\"\n",
    "        Generates an upsert query.\n",
    "\n",
    "        Returns:\n",
    "            str: The upsert query.\n",
    "        \"\"\"\n",
    "        return \"INSERT INTO {table_name} (id, metadata, contents, embedding) VALUES ($1, $2, $3, $4) ON CONFLICT DO NOTHING\".format(table_name=self._quote_ident(self.table_name))\n",
    "\n",
    "    def get_approx_count_query(self):\n",
    "        \"\"\"\n",
    "        Generate a query to find the approximate count of records in the table.\n",
    "\n",
    "        Returns:\n",
    "            str: the query.\n",
    "        \"\"\"\n",
    "        #todo optimize with approx\n",
    "        return \"SELECT COUNT(*) as cnt FROM {table_name}\".format(table_name=self._quote_ident(self.table_name))\n",
    "\n",
    "    #| export\n",
    "    def get_create_query(self):\n",
    "        \"\"\"\n",
    "        Generates a query to create the tables, indexes, and extensions needed to store the vector data.\n",
    "\n",
    "        Returns:\n",
    "            str: The create table query.\n",
    "        \"\"\"\n",
    "        return '''\n",
    "CREATE EXTENSION IF NOT EXISTS vector;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    id UUID PRIMARY KEY,\n",
    "    metadata JSONB,\n",
    "    contents TEXT,\n",
    "    embedding VECTOR({dimensions})\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS {index_name} ON {table_name} USING GIN(metadata jsonb_path_ops);\n",
    "'''.format(table_name=self._quote_ident(self.table_name), index_name=self._quote_ident(self.table_name+\"_meta_idx\"), dimensions=self.num_dimensions)\n",
    "\n",
    "    def _get_embedding_index_name(self):\n",
    "        return self._quote_ident(self.table_name+\"_embedding_idx\")\n",
    "    \n",
    "    def drop_embedding_index_query(self):\n",
    "        return \"DROP INDEX IF EXISTS {index_name};\".format(index_name=self._get_embedding_index_name())\n",
    "\n",
    "    def delete_all_query(self):\n",
    "        return \"TRUNCATE {table_name};\".format(table_name=self._quote_ident(self.table_name))\n",
    "\n",
    "    def delete_by_ids_query(self, id: List[uuid.UUID]) ->  Tuple[str, List]:\n",
    "       query = \"DELETE FROM {table_name} WHERE id = ANY($1::uuid[]);\".format(table_name=self._quote_ident(self.table_name))\n",
    "       return (query, [id])\n",
    "\n",
    "    def delete_by_metadata_query (self, filter: Union[Dict[str, str], List[Dict[str, str]]]) -> Tuple[str, List]:\n",
    "        params = []\n",
    "        (where, params) = self._where_clause_for_filter(params, filter)\n",
    "        query = \"DELETE FROM {table_name} WHERE {where};\".format(table_name=self._quote_ident(self.table_name), where=where)\n",
    "        return (query, params) \n",
    "\n",
    "    def drop_table_query(self):\n",
    "        return \"DROP TABLE IF EXISTS {table_name};\".format(table_name=self._quote_ident(self.table_name))\n",
    "       \n",
    "    def create_ivfflat_index_query(self, num_records):\n",
    "        \"\"\"\n",
    "        Generates an ivfflat index creation query.\n",
    "\n",
    "        Args:\n",
    "            num_records (int): The number of records in the table.\n",
    "\n",
    "        Returns:\n",
    "            str: The index creation query.\n",
    "        \"\"\"\n",
    "        column_name = \"embedding\" \n",
    "\n",
    "        index_method = \"invalid\"\n",
    "        if self.distance_type == \"<->\":\n",
    "            index_method = \"vector_l2_ops\"\n",
    "        elif self.distance_type == \"<#>\":\n",
    "            index_method = \"vector_ip_ops\"\n",
    "        elif self.distance_type == \"<=>\":\n",
    "            index_method = \"vector_cosine_ops\"\n",
    "        else:\n",
    "            raise ValueError(f\"unrecognized operator {query_operator}\")\n",
    "        \n",
    "        num_lists = num_records / 1000\n",
    "        if num_lists < 10:\n",
    "            num_lists = 10\n",
    "        if num_records > 1000000:\n",
    "            num_lists = math.sqrt(num_records)\n",
    "\n",
    "        return \"CREATE INDEX {index_name} ON {table_name} USING ivfflat ({column_name} {index_method}) WITH (lists = {num_lists});\"\\\n",
    "        .format(index_name=self._get_embedding_index_name(), table_name=self._quote_ident(self.table_name), column_name=self._quote_ident(column_name), index_method=index_method, num_lists=num_lists)\n",
    "\n",
    "    def _where_clause_for_filter(self, params: List, filter: Optional[Union[Dict[str, str], List[Dict[str, str]]]]) -> Tuple[str, List]:\n",
    "        if isinstance(filter, dict):\n",
    "            where = \"metadata @> ${index}\".format(index=len(params)+1)\n",
    "            json_object = json.dumps(filter)\n",
    "            params = params + [json_object]\n",
    "        elif isinstance(filter, list):\n",
    "            any_params = []\n",
    "            for idx, filter_dict in enumerate(filter, start=len(params) + 1):\n",
    "                any_params.append(json.dumps(filter_dict))\n",
    "            where = \"metadata @> ANY(${index}::jsonb[])\".format(index=len(params) + 1)\n",
    "            params = params + [any_params]\n",
    "        else:\n",
    "            where = \"TRUE\"\n",
    "\n",
    "        return (where, params) \n",
    "\n",
    "    def search_query(self, query_embedding: List[float], k: int=10, filter: Optional[Union[Dict[str, str], List[Dict[str, str]]]] = None) -> Tuple[str, List]:\n",
    "        \"\"\"\n",
    "        Generates a similarity query.\n",
    "\n",
    "        Args:\n",
    "            query_embedding (List[float]): The query embedding vector.\n",
    "            k (int, optional): The number of nearest neighbors to retrieve. Default is 10.\n",
    "            filter (Optional[dict], optional): A filter for metadata. Default is None.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, List]: A tuple containing the query and parameters.\n",
    "        \"\"\"\n",
    "        params = []\n",
    "        distance = \"embedding {op} ${index}\".format(op=self.distance_type, index=len(params)+1)\n",
    "        params = params + [query_embedding]\n",
    "\n",
    "        (where, params) = self._where_clause_for_filter(params, filter)\n",
    "\n",
    "        query = '''\n",
    "        SELECT\n",
    "            id, metadata, contents, embedding, {distance} as distance\n",
    "        FROM\n",
    "           {table_name}\n",
    "        WHERE \n",
    "           {where}\n",
    "        ORDER BY {distance} ASC\n",
    "        LIMIT {k}\n",
    "        '''.format(distance=distance, where=where, table_name=self._quote_ident(self.table_name), k=k)\n",
    "        return (query, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L87){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QueryBuilder.get_create_query\n",
       "\n",
       ">      QueryBuilder.get_create_query ()\n",
       "\n",
       "Generates a query to create the tables, indexes, and extensions needed to store the vector data.\n",
       "\n",
       "Returns:\n",
       "    str: The create table query."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L87){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QueryBuilder.get_create_query\n",
       "\n",
       ">      QueryBuilder.get_create_query ()\n",
       "\n",
       "Generates a query to create the tables, indexes, and extensions needed to store the vector data.\n",
       "\n",
       "Returns:\n",
       "    str: The create table query."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(QueryBuilder.get_create_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Async(QueryBuilder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        service_url: str,\n",
    "        table_name: str,\n",
    "        num_dimensions: int,\n",
    "        distance_type: str = 'cosine') -> None:\n",
    "            \"\"\"\n",
    "            Initializes a async client for storing vector data.\n",
    "    \n",
    "            Args:\n",
    "                service_url (str): The connection string for the database.\n",
    "                table_name (str): The name of the table.\n",
    "                num_dimensions (int): The number of dimensions for the embedding vector.\n",
    "                distance_type (str, optional): The distance type for indexing. Default is 'cosine' or '<=>'.\n",
    "            \"\"\"\n",
    "            self.builder = QueryBuilder(table_name,num_dimensions, distance_type)\n",
    "            self.service_url = service_url\n",
    "            self.pool = None\n",
    "            \n",
    "    async def connect(self):\n",
    "        \"\"\"\n",
    "        Establishes a connection to a PostgreSQL database using asyncpg.\n",
    "\n",
    "        Returns:\n",
    "            asyncpg.Connection: The established database connection.\n",
    "        \"\"\"\n",
    "        if self.pool == None:\n",
    "            async def init(conn):\n",
    "                await register_vector(conn)\n",
    "                #decode to a dict, but accept a string as input in upsert\n",
    "                await conn.set_type_codec(\n",
    "                    'jsonb',\n",
    "                    encoder=str,\n",
    "                    decoder=json.loads,\n",
    "                    schema='pg_catalog')\n",
    "\n",
    "            self.pool = await asyncpg.create_pool(dsn=self.service_url, init=init)\n",
    "        return self.pool.acquire()\n",
    "\n",
    "    async def table_is_empty(self):\n",
    "        \"\"\"\n",
    "        Checks if the table is empty.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the table is empty, False otherwise.\n",
    "        \"\"\"\n",
    "        query = self.builder.get_row_exists_query()\n",
    "        async with await self.connect() as pool:\n",
    "            rec = await pool.fetchrow(query)\n",
    "            return rec == None\n",
    "\n",
    "    def _convert_record_meta_to_json(item):\n",
    "        if not isinstance(item[1], dict):\n",
    "            raise ValueError(\"Cannot mix dictionary and string metadata fields in the same upsert\")\n",
    "        return (item[0], json.dumps(item[1]), item[2], item[3])\n",
    "\n",
    "\n",
    "    async def upsert(self, records):\n",
    "        \"\"\"\n",
    "        Performs upsert operation for multiple records.\n",
    "\n",
    "        Args:\n",
    "            records: Records to upsert.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if isinstance(records[0][1], dict):\n",
    "            records = list(map(lambda item: Async._convert_record_meta_to_json(item), records))\n",
    "        query = self.builder.get_upsert_query()\n",
    "        async with await self.connect() as pool:\n",
    "            await pool.executemany(query, records)\n",
    "\n",
    "    async def create_tables(self):\n",
    "        \"\"\"\n",
    "        Creates necessary tables.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        query = self.builder.get_create_query()\n",
    "        async with await self.connect() as pool:\n",
    "            await pool.execute(query)\n",
    "\n",
    "    async def delete_all(self, drop_index=True):\n",
    "        \"\"\"\n",
    "        Deletes all data. Also drops the index if `drop_index` is true.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if drop_index:\n",
    "            await self.drop_embedding_index();\n",
    "        query = self.builder.delete_all_query()\n",
    "        async with await self.connect() as pool:\n",
    "            await pool.execute(query)\n",
    "\n",
    "    async def delete_by_ids(self, id: List[uuid.UUID]):\n",
    "        \"\"\"\n",
    "        Delete records by id.\n",
    "        \"\"\"\n",
    "        (query, params) = self.builder.delete_by_ids_query(id)\n",
    "        async with await self.connect() as pool:\n",
    "            return await pool.fetch(query, *params)\n",
    "\n",
    "    async def delete_by_metadata(self, filter: Union[Dict[str, str], List[Dict[str, str]]]):\n",
    "        \"\"\"\n",
    "        Delete records by metadata filters.\n",
    "        \"\"\"\n",
    "        (query, params) = self.builder.delete_by_metadata_query(filter)\n",
    "        async with await self.connect() as pool:\n",
    "            return await pool.fetch(query, *params)\n",
    "\n",
    "\n",
    "    async def drop_table(self):\n",
    "        \"\"\"\n",
    "        Drops the table\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        query = self.builder.drop_table_query()\n",
    "        async with await self.connect() as pool:\n",
    "            await pool.execute(query)\n",
    "\n",
    "    async def _get_approx_count(self):\n",
    "        \"\"\"\n",
    "        Retrieves an approximate count of records in the table.\n",
    "\n",
    "        Returns:\n",
    "            int: Approximate count of records.\n",
    "        \"\"\"\n",
    "        query = self.builder.get_approx_count_query()\n",
    "        async with await self.connect() as pool:\n",
    "            rec = await pool.fetchrow(query)\n",
    "            return rec[0]\n",
    "\n",
    "    async def drop_embedding_index(self):\n",
    "        \"\"\"\n",
    "        Drop any index on the emedding\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        query = self.builder.drop_embedding_index_query()\n",
    "        async with await self.connect() as pool:\n",
    "            await pool.execute(query)\n",
    "    \n",
    "    async def create_ivfflat_index(self, num_records=None):\n",
    "        \"\"\"\n",
    "        Creates an ivfflat index for the table.\n",
    "\n",
    "        Args:\n",
    "            num_records (int, optional): The number of records. If None, it's calculated. Default is None.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if num_records == None:\n",
    "            num_records = await self._get_approx_count()\n",
    "        query = self.builder.create_ivfflat_index_query(num_records)\n",
    "        async with await self.connect() as pool:\n",
    "            await pool.execute(query)\n",
    "\n",
    "    async def search(self, \n",
    "                     query_embedding: List[float], # vector to search for\n",
    "                     k: int=10, # The number of nearest neighbors to retrieve. Default is 10.\n",
    "                     filter: Optional[Union[Dict[str, str], List[Dict[str, str]]]] = None): # A filter for metadata. Default is None.\n",
    "        \"\"\"\n",
    "        Retrieves similar records using a similarity query.\n",
    "\n",
    "        Returns:\n",
    "            List: List of similar records.\n",
    "        \"\"\"\n",
    "        (query, params) = self.builder.search_query(query_embedding, k, filter)\n",
    "        async with await self.connect() as pool:\n",
    "            return await pool.fetch(query, *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L256){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Async.create_tables\n",
       "\n",
       ">      Async.create_tables ()\n",
       "\n",
       "Creates necessary tables.\n",
       "\n",
       "Returns:\n",
       "    None"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L256){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Async.create_tables\n",
       "\n",
       ">      Async.create_tables ()\n",
       "\n",
       "Creates necessary tables.\n",
       "\n",
       "Returns:\n",
       "    None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Async.create_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L256){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Async.create_tables\n",
       "\n",
       ">      Async.create_tables ()\n",
       "\n",
       "Creates necessary tables.\n",
       "\n",
       "Returns:\n",
       "    None"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L256){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Async.create_tables\n",
       "\n",
       ">      Async.create_tables ()\n",
       "\n",
       "Creates necessary tables.\n",
       "\n",
       "Returns:\n",
       "    None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Async.create_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L319){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Async.search\n",
       "\n",
       ">      Async.search (query_embedding:List[float], k:int=10,\n",
       ">                    filter:Union[Dict[str,str],List[Dict[str,str]],NoneType]=No\n",
       ">                    ne)\n",
       "\n",
       "Retrieves similar records using a similarity query.\n",
       "\n",
       "Returns:\n",
       "    List: List of similar records."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L319){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Async.search\n",
       "\n",
       ">      Async.search (query_embedding:List[float], k:int=10,\n",
       ">                    filter:Union[Dict[str,str],List[Dict[str,str]],NoneType]=No\n",
       ">                    ne)\n",
       "\n",
       "Retrieves similar records using a similarity query.\n",
       "\n",
       "Returns:\n",
       "    List: List of similar records."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Async.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "con = await asyncpg.connect(service_url)\n",
    "await con.execute(\"DROP TABLE IF EXISTS data_table;\")\n",
    "await con.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec  = Async(service_url, \"data_table\", 2)\n",
    "await vec.create_tables()\n",
    "empty = await vec.table_is_empty()\n",
    "assert empty\n",
    "await vec.upsert([(uuid.uuid4(), {\"key\" : \"val\"}, \"the brown fox\", [1.0,1.2])])\n",
    "empty = await vec.table_is_empty()\n",
    "assert not empty\n",
    "\n",
    "await vec.upsert([\\\n",
    "    (uuid.uuid4(), '''{\"key\":\"val\"}''', \"the brown fox\", [1.0,1.3]),\\\n",
    "    (uuid.uuid4(), '''{\"key\":\"val2\"}''', \"the brown fox\", [1.0,1.4]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.5]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.6]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.6]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val2\"}''', \"the brown fox\", [1.0,1.7]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.9]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,100.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,101.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key_1\":\"val_1\", \"key_2\":\"val_2\"}''', \"the brown fox\", [1.0,1.8]),\\\n",
    "])\n",
    "\n",
    "await vec.create_ivfflat_index()\n",
    "await vec.drop_embedding_index()\n",
    "await vec.create_ivfflat_index(100)\n",
    "\n",
    "rec = await vec.search([1.0, 2.0])\n",
    "assert len(rec) == 10\n",
    "rec = await vec.search([1.0, 2.0], k=4)\n",
    "assert len(rec) == 4\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter={\"key2\":\"val2\"})\n",
    "assert len(rec) == 1\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter={\"key2\":\"does not exist\"})\n",
    "assert len(rec) == 0\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter={\"key_1\":\"val_1\"})\n",
    "assert len(rec) == 1\n",
    "rec = await vec.search([1.0, 2.0], filter={\"key_1\":\"val_1\", \"key_2\":\"val_2\"})\n",
    "assert len(rec) == 1\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter={\"key_1\":\"val_1\", \"key_2\":\"val_3\"})\n",
    "assert len(rec) == 0\n",
    "\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "assert len(rec) == 2\n",
    "\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}, {\"no such key\": \"no such val\"}])\n",
    "assert len(rec) == 2\n",
    "\n",
    "assert isinstance(rec[0][SEARCH_RESULT_METADATA_IDX], dict)\n",
    "\n",
    "try:\n",
    "    # can't upsert using both keys and dictionaries\n",
    "    await vec.upsert([ \\\n",
    "      (uuid.uuid4(), {\"key\" : \"val\"}, \"the brown fox\", [1.0,1.2]), \\\n",
    "      (uuid.uuid4(), '''{\"key2\":\"val\"}''' , \"the brown fox\", [1.0,1.2])\\\n",
    "    ])\n",
    "    assert False\n",
    "except ValueError as e:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # can't upsert using both keys and dictionaries opposite order\n",
    "    await vec.upsert([ \\\n",
    "      (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.2]), \\\n",
    "      (uuid.uuid4(),  {\"key\" : \"val\"}, \"the brown fox\", [1.0,1.2])\\\n",
    "    ])\n",
    "    assert False\n",
    "except BaseException as e:\n",
    "    pass\n",
    "\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "assert len(rec) == 2\n",
    "await vec.delete_by_ids([rec[0][SEARCH_RESULT_ID_IDX]])\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "assert len(rec) == 1\n",
    "await vec.delete_by_metadata([{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "assert len(rec) == 0\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter=[{\"key2\":\"val\"}])\n",
    "assert len(rec) == 4\n",
    "await vec.delete_by_metadata([{\"key2\":\"val\"}])\n",
    "rec = await vec.search([1.0, 2.0], k=4, filter=[{\"key2\":\"val\"}])\n",
    "assert len(rec) == 0\n",
    "\n",
    "assert not await vec.table_is_empty()\n",
    "await vec.delete_all()\n",
    "assert await vec.table_is_empty()\n",
    "\n",
    "await vec.drop_table()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import psycopg2.pool\n",
    "from contextlib import contextmanager\n",
    "import psycopg2.extras\n",
    "import pgvector.psycopg2\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Sync:\n",
    "    translated_queries = {}\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        service_url: str,\n",
    "        table_name: str,\n",
    "        num_dimensions: int,\n",
    "        distance_type: str = 'cosine') -> None:\n",
    "            self.builder = QueryBuilder(table_name,num_dimensions, distance_type)\n",
    "            self.service_url = service_url\n",
    "            self.pool = None\n",
    "            psycopg2.extras.register_uuid()\n",
    "\n",
    "    \n",
    "    @contextmanager\n",
    "    def connect(self):\n",
    "        \"\"\"\n",
    "        Establishes a connection to a PostgreSQL database using psycopg2 and allows it's\n",
    "        use in a context manager.\n",
    "        \"\"\"\n",
    "        if self.pool == None:\n",
    "            self.pool = psycopg2.pool.SimpleConnectionPool(1, 10, dsn=self.service_url)\n",
    "        \n",
    "        connection = self.pool.getconn()\n",
    "        pgvector.psycopg2.register_vector(connection)\n",
    "        try:\n",
    "            yield connection\n",
    "            connection.commit()\n",
    "        finally:            \n",
    "            self.pool.putconn(connection)\n",
    "\n",
    "    def _translate_to_pyformat(self, query_string, params):\n",
    "        \"\"\"\n",
    "        Translates dollar sign number parameters and list parameters to pyformat strings.\n",
    "\n",
    "        Args:\n",
    "            query_string (str): The query string with parameters.\n",
    "            params (list): List of parameter values.\n",
    "    \n",
    "        Returns:\n",
    "            str: The query string with translated pyformat parameters.\n",
    "            dict: A dictionary mapping parameter numbers to their values.\n",
    "        \"\"\"\n",
    "        \n",
    "        translated_params = {}\n",
    "        if params != None:\n",
    "            for idx, param in enumerate(params):\n",
    "                translated_params[str(idx+1)] = param\n",
    "\n",
    "        if query_string in self.translated_queries:\n",
    "            return self.translated_queries[query_string], translated_params\n",
    "\n",
    "        dollar_params = re.findall(r'\\$[0-9]+', query_string) \n",
    "        translated_string = query_string \n",
    "        for dollar_param in dollar_params:\n",
    "            param_number = int(dollar_param[1:])  # Extract the number after the $\n",
    "            if params != None:\n",
    "                pyformat_param = '%s' if param_number == 0 else f'%({param_number})s'\n",
    "            else:\n",
    "                pyformat_param = '%s'\n",
    "            translated_string = translated_string.replace(dollar_param, pyformat_param)\n",
    "\n",
    "        self.translated_queries[query_string] = translated_string \n",
    "        return self.translated_queries[query_string], translated_params\n",
    "        \n",
    "    def table_is_empty(self):\n",
    "        \"\"\"\n",
    "        Checks if the table is empty.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the table is empty, False otherwise.\n",
    "        \"\"\"\n",
    "        query = self.builder.get_row_exists_query()\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query)\n",
    "                rec = cur.fetchone()\n",
    "                return rec == None\n",
    "\n",
    "    def _convert_record_meta_to_json(item):\n",
    "        if not isinstance(item[1], dict):\n",
    "            raise ValueError(\"Cannot mix dictionary and string metadata fields in the same upsert\")\n",
    "        return (item[0], json.dumps(item[1]), item[2], item[3])\n",
    "    \n",
    "    def upsert(self, records):\n",
    "        \"\"\"\n",
    "        Performs upsert operation for multiple records.\n",
    "\n",
    "        Args:\n",
    "            records: Records to upsert.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if isinstance(records[0][1], dict):\n",
    "            records = list(map(lambda item: Async._convert_record_meta_to_json(item), records))\n",
    "                    \n",
    "        query = self.builder.get_upsert_query()\n",
    "        query, _ = self._translate_to_pyformat(query, None)\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.executemany(query, records)\n",
    "\n",
    "    def create_tables(self):\n",
    "        \"\"\"\n",
    "        Creates necessary tables.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        query = self.builder.get_create_query()\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query)\n",
    "\n",
    "    def delete_all(self, drop_index=True):\n",
    "        \"\"\"\n",
    "        Deletes all data. Also drops the index if `drop_index` is true.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if drop_index:\n",
    "            self.drop_embedding_index();\n",
    "        query = self.builder.delete_all_query()\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query)\n",
    "    \n",
    "    def delete_by_ids(self, id: List[uuid.UUID]):\n",
    "        \"\"\"\n",
    "        Delete records by id.\n",
    "        \"\"\"\n",
    "        (query, params) = self.builder.delete_by_ids_query(id)\n",
    "        query, params = self._translate_to_pyformat(query, params)\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query, params)\n",
    "\n",
    "    def delete_by_metadata(self, filter: Union[Dict[str, str], List[Dict[str, str]]]):\n",
    "        \"\"\"\n",
    "        Delete records by metadata filters.\n",
    "        \"\"\"\n",
    "        (query, params) = self.builder.delete_by_metadata_query(filter)\n",
    "        query, params = self._translate_to_pyformat(query, params)\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query, params)\n",
    "\n",
    "    def drop_table(self):\n",
    "        \"\"\"\n",
    "        Drops the table\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        query = self.builder.drop_table_query()\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query)\n",
    "\n",
    "    def _get_approx_count(self):\n",
    "        \"\"\"\n",
    "        Retrieves an approximate count of records in the table.\n",
    "\n",
    "        Returns:\n",
    "            int: Approximate count of records.\n",
    "        \"\"\"\n",
    "        query = self.builder.get_approx_count_query()\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query)\n",
    "                rec = cur.fetchone()\n",
    "                return rec[0]\n",
    "\n",
    "    def drop_embedding_index(self):\n",
    "        \"\"\"\n",
    "        Drop any index on the emedding\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        query = self.builder.drop_embedding_index_query()\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query)\n",
    "    \n",
    "    def create_ivfflat_index(self, num_records=None):\n",
    "        \"\"\"\n",
    "        Creates an ivfflat index for the table.\n",
    "\n",
    "        Args:\n",
    "            num_records (int, optional): The number of records. If None, it's calculated. Default is None.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if num_records == None:\n",
    "            num_records = self._get_approx_count()\n",
    "        query = self.builder.create_ivfflat_index_query(num_records)\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query)\n",
    "\n",
    "    def search(self, query_embedding: List[float], k: int=10, filter: Optional[Union[Dict[str, str], List[Dict[str, str]]]] = None):\n",
    "        \"\"\"\n",
    "        Retrieves similar records using a similarity query.\n",
    "\n",
    "        Args:\n",
    "            query_embedding (List[float]): The query embedding vector.\n",
    "            k (int, optional): The number of nearest neighbors to retrieve. Default is 10.\n",
    "            filter (Optional[dict], optional): A filter for metadata. Default is None.\n",
    "\n",
    "        Returns:\n",
    "            List: List of similar records.\n",
    "        \"\"\"\n",
    "        (query, params) = self.builder.search_query(np.array(query_embedding), k, filter)\n",
    "        query, params = self._translate_to_pyformat(query, params)\n",
    "        with self.connect() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query, params)\n",
    "                return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L446){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Sync.create_tables\n",
       "\n",
       ">      Sync.create_tables ()\n",
       "\n",
       "Creates necessary tables.\n",
       "\n",
       "Returns:\n",
       "    None"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L446){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Sync.create_tables\n",
       "\n",
       ">      Sync.create_tables ()\n",
       "\n",
       "Creates necessary tables.\n",
       "\n",
       "Returns:\n",
       "    None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Sync.create_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L427){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Sync.upsert\n",
       "\n",
       ">      Sync.upsert (records)\n",
       "\n",
       "Performs upsert operation for multiple records.\n",
       "\n",
       "Args:\n",
       "    records: Records to upsert.\n",
       "\n",
       "Returns:\n",
       "    None"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L427){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Sync.upsert\n",
       "\n",
       ">      Sync.upsert (records)\n",
       "\n",
       "Performs upsert operation for multiple records.\n",
       "\n",
       "Args:\n",
       "    records: Records to upsert.\n",
       "\n",
       "Returns:\n",
       "    None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Sync.upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L515){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Sync.search\n",
       "\n",
       ">      Sync.search (query_embedding:List[float], k:int=10,\n",
       ">                   filter:Union[Dict[str,str],List[Dict[str,str]],NoneType]=Non\n",
       ">                   e)\n",
       "\n",
       "Retrieves similar records using a similarity query.\n",
       "\n",
       "Args:\n",
       "    query_embedding (List[float]): The query embedding vector.\n",
       "    k (int, optional): The number of nearest neighbors to retrieve. Default is 10.\n",
       "    filter (Optional[dict], optional): A filter for metadata. Default is None.\n",
       "\n",
       "Returns:\n",
       "    List: List of similar records."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/timescale/python-vector/blob/main/timescale_vector/client.py#L515){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Sync.search\n",
       "\n",
       ">      Sync.search (query_embedding:List[float], k:int=10,\n",
       ">                   filter:Union[Dict[str,str],List[Dict[str,str]],NoneType]=Non\n",
       ">                   e)\n",
       "\n",
       "Retrieves similar records using a similarity query.\n",
       "\n",
       "Args:\n",
       "    query_embedding (List[float]): The query embedding vector.\n",
       "    k (int, optional): The number of nearest neighbors to retrieve. Default is 10.\n",
       "    filter (Optional[dict], optional): A filter for metadata. Default is None.\n",
       "\n",
       "Returns:\n",
       "    List: List of similar records."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Sync.search)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "con = await asyncpg.connect(service_url)\n",
    "await con.execute(\"DROP TABLE IF EXISTS data_table;\")\n",
    "await con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec  = Sync(service_url, \"data_table\", 2)\n",
    "vec.create_tables()\n",
    "empty = vec.table_is_empty()\n",
    "\n",
    "assert empty\n",
    "vec.upsert([(uuid.uuid4(), {\"key\" : \"val\"}, \"the brown fox\", [1.0,1.2])])\n",
    "empty = vec.table_is_empty()\n",
    "assert not empty\n",
    "\n",
    "vec.upsert([\\\n",
    "    (uuid.uuid4(), '''{\"key\":\"val\"}''', \"the brown fox\", [1.0,1.3]),\\\n",
    "    (uuid.uuid4(), '''{\"key\":\"val2\"}''', \"the brown fox\", [1.0,1.4]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.5]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.6]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.6]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val2\"}''', \"the brown fox\", [1.0,1.7]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.9]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,100.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,101.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.8]),\\\n",
    "    (uuid.uuid4(), '''{\"key_1\":\"val_1\", \"key_2\":\"val_2\"}''', \"the brown fox\", [1.0,1.8]),\\\n",
    "])\n",
    "\n",
    "vec.create_ivfflat_index()\n",
    "vec.drop_embedding_index()\n",
    "vec.create_ivfflat_index(10)\n",
    "\n",
    "rec = vec.search([1.0, 2.0])\n",
    "assert len(rec) == 10\n",
    "rec = vec.search(np.array([1.0, 2.0]))\n",
    "assert len(rec) == 10\n",
    "rec = vec.search([1.0, 2.0], k=4)\n",
    "assert len(rec) == 4\n",
    "rec = vec.search([1.0, 2.0], k=4, filter={\"key2\":\"val2\"})\n",
    "assert len(rec) == 1\n",
    "rec = vec.search([1.0, 2.0], k=4, filter={\"key2\":\"does not exist\"})\n",
    "assert len(rec) == 0\n",
    "rec = vec.search([1.0, 2.0], k=4, filter={\"key_1\":\"val_1\"})\n",
    "assert len(rec) == 1\n",
    "rec = vec.search([1.0, 2.0], filter={\"key_1\":\"val_1\", \"key_2\":\"val_2\"})\n",
    "assert len(rec) == 1\n",
    "rec = vec.search([1.0, 2.0], k=4, filter={\"key_1\":\"val_1\", \"key_2\":\"val_3\"})\n",
    "assert len(rec) == 0\n",
    "\n",
    "rec = vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "assert len(rec) == 2\n",
    "\n",
    "rec = vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}, {\"no such key\": \"no such val\"}])\n",
    "assert len(rec) == 2\n",
    "\n",
    "try:\n",
    "    # can't upsert using both keys and dictionaries\n",
    "    await vec.upsert([ \\\n",
    "      (uuid.uuid4(), {\"key\" : \"val\"}, \"the brown fox\", [1.0,1.2]), \\\n",
    "      (uuid.uuid4(), '''{\"key2\":\"val\"}''' , \"the brown fox\", [1.0,1.2])\\\n",
    "    ])\n",
    "    assert False\n",
    "except ValueError as e:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # can't upsert using both keys and dictionaries opposite order\n",
    "    await vec.upsert([ \\\n",
    "      (uuid.uuid4(), '''{\"key2\":\"val\"}''', \"the brown fox\", [1.0,1.2]), \\\n",
    "      (uuid.uuid4(),  {\"key\" : \"val\"}, \"the brown fox\", [1.0,1.2])\\\n",
    "    ])\n",
    "    assert False\n",
    "except BaseException as e:\n",
    "    pass\n",
    "\n",
    "rec = vec.search([1.0, 2.0], filter={\"key_1\":\"val_1\", \"key_2\":\"val_2\"})\n",
    "assert rec[0][SEARCH_RESULT_CONTENTS_IDX] == 'the brown fox'\n",
    "assert rec[0][SEARCH_RESULT_METADATA_IDX] == {'key_1': 'val_1', 'key_2': 'val_2'}\n",
    "assert isinstance(rec[0][SEARCH_RESULT_METADATA_IDX], dict)\n",
    "assert rec[0][SEARCH_RESULT_DISTANCE_IDX] == 0.0009438353921149556\n",
    "\n",
    "rec = vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "len(rec) == 2\n",
    "vec.delete_by_ids([rec[0][SEARCH_RESULT_ID_IDX]])\n",
    "rec = vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "assert len(rec) == 1\n",
    "vec.delete_by_metadata([{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "rec = vec.search([1.0, 2.0], k=4, filter=[{\"key_1\":\"val_1\"}, {\"key2\":\"val2\"}])\n",
    "assert len(rec) == 0\n",
    "rec = vec.search([1.0, 2.0], k=4, filter=[{\"key2\":\"val\"}])\n",
    "assert len(rec) == 4\n",
    "vec.delete_by_metadata([{\"key2\":\"val\"}])\n",
    "rec = vec.search([1.0, 2.0], k=4, filter=[{\"key2\":\"val\"}])\n",
    "len(rec) == 0\n",
    "\n",
    "assert not vec.table_is_empty()\n",
    "vec.delete_all()\n",
    "assert vec.table_is_empty()\n",
    "\n",
    "vec.drop_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
